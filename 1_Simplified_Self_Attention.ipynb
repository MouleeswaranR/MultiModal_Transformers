{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qG6LusJEvcTO"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#each row corresponds to a word\n",
        "inputs=torch.tensor(\n",
        "    [\n",
        " [ 0.42, -1.37,  2.15],\n",
        " [ 1.08,  0.56, -0.91],\n",
        " [-0.73,  1.94,  0.28],\n",
        " [ 2.61, -0.44, -1.12],\n",
        " [ 0.09,  0.87,  1.53],\n",
        " [-1.68,  0.31, -0.26]\n",
        "]\n",
        ")\n",
        "\n",
        "words=['Dream','big','and','work','for','it']"
      ],
      "metadata": {
        "id": "9rCWn62avg0O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating magnitude of each vector\n",
        "# formula: square root of sum of squares of all values in each row\n",
        "magnitudes=torch.norm(inputs,dim=1)#dim=1 represents the calculating along all columns in each row\n",
        "\n",
        "for word,magnitude in zip(words,magnitudes):\n",
        "  print(f\"{word}: {magnitude.item(): .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw4LXa-AvyYZ",
        "outputId": "26611fbb-a21c-4218-bb7a-47b9e2e801f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dream:  2.5838\n",
            "big:  1.5192\n",
            "and:  2.0916\n",
            "work:  2.8740\n",
            "for:  1.7624\n",
            "it:  1.7280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#taking 2nd token as query\n",
        "\n",
        "query=inputs[1]#2nd tokemn input embedding\n",
        "\n",
        "\n",
        "#creating a empty array of shape of inputs' row value\n",
        "attn_scores2=torch.empty(inputs.shape[0])\n",
        "\n",
        "for i,x_i in enumerate(inputs):\n",
        "  attn_scores2[i]=torch.dot(x_i,query)\n",
        "\n",
        "print(attn_scores2)\n",
        "#attn_scores2 represents how each token is related to 2nd token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXhbf_pTwRXn",
        "outputId": "3867ecf8-bab9-4c3a-80de-a798de3a160c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.2701,  2.3081,  0.0432,  3.5916, -0.8079, -1.4042])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating attention weights with simple normalization\n",
        "\n",
        "attn_weights2temp=attn_scores2/attn_scores2.sum()\n",
        "\n",
        "print(\"Attention weights for 2nd token: \",attn_weights2temp)\n",
        "print(\"Sum: \",attn_weights2temp.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GwBdnXxQfE",
        "outputId": "146d8910-7107-4321-cf7f-b6194e6f5218"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights for 2nd token:  tensor([-1.5541,  1.5801,  0.0296,  2.4588, -0.5531, -0.9613])\n",
            "Sum:  tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating attention weights with softmax\n",
        "\n",
        "attn_weights2=torch.softmax(attn_scores2,dim=-1)\n",
        "print(\"Attention weights for 2nd token with softmax: \",attn_weights2)\n",
        "print(\"Sum: \",attn_weights2.sum())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5mSfcdax9Wt",
        "outputId": "27f44c12-4b74-44ed-8750-e1aa5047cbdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights for 2nd token with softmax:  tensor([0.0021, 0.2087, 0.0217, 0.7532, 0.0093, 0.0051])\n",
            "Sum:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating attention scores for each token with each token\n",
        "attn_scores=inputs @ inputs.T\n",
        "#each row represents how much that row's token related with all tokens including itself in each column\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IcTpzZSyggF",
        "outputId": "955a1bde-9feb-434b-8739-24132500633d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.6758, -2.2701, -2.3624, -0.7090,  2.1354, -1.6893],\n",
            "        [-2.2701,  2.3081,  0.0432,  3.5916, -0.8079, -1.4042],\n",
            "        [-2.3624,  0.0432,  4.3749, -3.0725,  2.0505,  1.7550],\n",
            "        [-0.7090,  3.5916, -3.0725,  8.2601, -1.8615, -4.2300],\n",
            "        [ 2.1354, -0.8079,  2.0505, -1.8615,  3.1059, -0.2793],\n",
            "        [-1.6893, -1.4042,  1.7550, -4.2300, -0.2793,  2.9861]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating attention weights\n",
        "attn_weights=torch.softmax(attn_scores,dim=-1)\n",
        "print(attn_weights)\n",
        "#each row sum is almost equal to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odKS-F6KytLv",
        "outputId": "24a04f15-0fa0-4514-a806-5e47d261c096"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.8837e-01, 1.2875e-04, 1.1740e-04, 6.1339e-04, 1.0545e-02, 2.3014e-04],\n",
            "        [2.1438e-03, 2.0868e-01, 2.1669e-02, 7.5316e-01, 9.2515e-03, 5.0961e-03],\n",
            "        [1.0002e-03, 1.1088e-02, 8.4348e-01, 4.9171e-04, 8.2528e-02, 6.1414e-02],\n",
            "        [1.2608e-04, 9.2974e-03, 1.1863e-05, 9.9052e-01, 3.9821e-05, 3.7281e-06],\n",
            "        [2.1194e-01, 1.1167e-02, 1.9469e-01, 3.8939e-03, 5.5936e-01, 1.8946e-02],\n",
            "        [6.8917e-03, 9.1653e-03, 2.1586e-01, 5.4315e-04, 2.8228e-02, 7.3931e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context vectors\n",
        "context_vecs=attn_weights @ inputs\n",
        "print(context_vecs)\n",
        "#each rows carries information about how that row's token is related to all the other tokens inclusing itself"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMiwPrAfzK-F",
        "outputId": "40757bd6-acc4-4dbb-fd2f-1a249859205c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4173, -1.3448,  2.1403],\n",
            "        [ 2.1685, -0.1658, -1.0099],\n",
            "        [-0.6978,  1.7318,  0.3380],\n",
            "        [ 2.5953, -0.4307, -1.1175],\n",
            "        [-0.0124,  0.5844,  1.3466],\n",
            "        [-1.3829,  0.6680, -0.0827]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0FKg6RRz6rq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}